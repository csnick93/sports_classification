{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SportsClassification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQCpLnWfZN6iXMdbvVPviS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csnick93/sports_classification/blob/main/SportsClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F4BAIHK1WCp"
      },
      "source": [
        "#TODO\n",
        "# - get the following to work\n",
        "#     - mixup, label smoothing and tta\n",
        "# - mixup, label smoothing\n",
        "#   - debug either in notebook or in terminal script why we are getting \n",
        "#       the weird prediction behavior\n",
        "#   - also understand using debugging what is happening\n",
        "# - tta\n",
        "#   - debug as well to understand why performance becomes so much worse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTydlW6uVNnx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhLh8UyrfaIV"
      },
      "source": [
        "from pathlib import Path\n",
        "cloud_dir = Path('/content/drive/My Drive/SportsClassification')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fL_Gu0Ejmf2"
      },
      "source": [
        "!rsync --info=progress2 ./drive/My\\ Drive/SportsClassification/data.zip . && unzip data.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LtF4CQXgTMT"
      },
      "source": [
        "!rsync --info=progress2 ./drive/My\\ Drive/SportsClassification/mlruns.zip . && unzip mlruns.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eurqmCKttaaP"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!rsync --info=progress2 ./drive/My\\ Drive/SportsClassification/kaggle.json ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzNSYYhMeEJ2"
      },
      "source": [
        "data_dir = Path('/content/data')\n",
        "mlflow_dir = Path('/content/mlruns')\n",
        "assert(data_dir.exists())\n",
        "assert(mlflow_dir.exists())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXBA_pf-GTQo"
      },
      "source": [
        "# Getting the code repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu5MCUqySiVQ"
      },
      "source": [
        "!pip install --upgrade pip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b-kHA30NyHn"
      },
      "source": [
        "!git clone https://github.com/csnick93/sports_classification.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4GCWRb3f8Ki"
      },
      "source": [
        "!pip install -q mlflow kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znMEZzUZNZhQ"
      },
      "source": [
        "!pip install fastai==2.1.8 nbdev --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpx2JGkGQrsJ"
      },
      "source": [
        "!pip install onnx onnxruntime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD-Rk7_oGY-E"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2J5lENEJltM"
      },
      "source": [
        "from fastai.vision.all import *\n",
        "from fastai.data.all import *\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import onnx\n",
        "import onnxruntime \n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgLvDXYNGbFK"
      },
      "source": [
        "# Experiment Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oExjfVpWvIi"
      },
      "source": [
        "#config\n",
        "class Config:\n",
        "  def __init__(self,\n",
        "              data_dir,\n",
        "              augmentations = False,\n",
        "              img_size = 224,  \n",
        "              num_epochs = 5,\n",
        "              num_freeze_epochs = 1,\n",
        "              model_arch = resnet18,\n",
        "              data_subset=False,\n",
        "              mixup_alpha=0,\n",
        "              multi_class=True):\n",
        "      self.data_dir = data_dir\n",
        "      self.augmentations = augmentations\n",
        "      self.img_size = img_size\n",
        "      self.num_epochs = num_epochs\n",
        "      self.num_freeze_epochs = num_freeze_epochs\n",
        "      self.model_arch = model_arch\n",
        "      self.data_subset = data_subset\n",
        "      self.mixup_alpha = mixup_alpha\n",
        "      self.multi_class=multi_class\n",
        "\n",
        "      if self.data_subset: \n",
        "        self.train_val_file = self.data_dir/'subset_train_val_data.csv'\n",
        "      else:\n",
        "        self.train_val_file = self.data_dir/'train_val_data.csv'\n",
        "\n",
        "\n",
        "  def __str__(self):\n",
        "    return '%s_%i_%i_%s_%s_%s'%(str(self.augmentations), self.img_size, \n",
        "                          self.num_epochs, str(self.model_arch).split(' ')[1],\n",
        "                          self.data_subset, self.multi_class)\n",
        "  \n",
        "  def mlflow_config(self):\n",
        "    return list(self.__dict__.items())\n",
        "  \n",
        "config = Config(data_dir, augmentations=True, img_size=224, \n",
        "                num_epochs=5, num_freeze_epochs = 5,\n",
        "                model_arch=resnet18, data_subset = True,\n",
        "                mixup_alpha = 0.0, multi_class=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1yVRoJElR2M"
      },
      "source": [
        "* For data subset:\n",
        "  * ResNet18:\n",
        "    * num_freeze_epochs: after epoch 8, starting to overfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg_qFvYhGd4Q"
      },
      "source": [
        "# Get Data and inspect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keeoyyGrLCQm"
      },
      "source": [
        "train_val_folder = get_image_files(config.data_dir/\"train\")\n",
        "train_val_data = pd.read_csv(config.train_val_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkyb3dLtLr8E"
      },
      "source": [
        "category_block = CategoryBlock\n",
        "label_reader = ColReader(1)\n",
        "if config.multi_class:\n",
        "  category_block = MultiCategoryBlock\n",
        "  label_reader = ColReader(1, label_delim=' ')\n",
        "  \n",
        "if config.augmentations:\n",
        "  data_block = DataBlock(blocks=(ImageBlock, category_block),\n",
        "                        splitter=ColSplitter(),\n",
        "                        get_x=ColReader(0, pref=config.data_dir),\n",
        "                        get_y=label_reader,\n",
        "                        item_tfms=Resize(2*config.img_size),\n",
        "                        batch_tfms=aug_transforms(size=config.img_size, \n",
        "                                                  min_scale=0.75)\n",
        "                        )\n",
        "else:\n",
        "  data_block = DataBlock(blocks=(ImageBlock, category_block),\n",
        "                        splitter=ColSplitter(),\n",
        "                        get_x=ColReader(0, pref=config.data_dir),\n",
        "                        get_y=label_reader,\n",
        "                        item_tfms=Resize(config.img_size)\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEVufc3FPI-8"
      },
      "source": [
        "dls = data_block.dataloaders(train_val_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__qCm_TBPLpE"
      },
      "source": [
        "dls.show_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtRebqLsq6KK"
      },
      "source": [
        "# mixup = MixUp(0.5)\n",
        "# learn = Learner(dls, config.model_arch, loss_func=CrossEntropyLossFlat(), cbs=[mixup])\n",
        "# learn.epoch,learn.training = 0,True\n",
        "# learn.dl = dls.train\n",
        "# b = dls.one_batch()\n",
        "# learn._split(b)\n",
        "# learn('before_batch')\n",
        "\n",
        "# _,axs = plt.subplots(3,3, figsize=(9,9))\n",
        "# dls.show_batch(b=(mixup.x,mixup.y), ctxs=axs.flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKnEnk87GgAg"
      },
      "source": [
        "# Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAUurXn_PcH0"
      },
      "source": [
        "metrics = error_rate\n",
        "monitor = 'error_rate'\n",
        "if config.multi_class:\n",
        "  metrics = partial(accuracy_multi, thresh=0.5)\n",
        "  monitor = 'accuracy_multi'\n",
        "if config.mixup_alpha > 0:\n",
        "  mixup = MixUp(alpha = config.mixup_alpha)\n",
        "  learn = cnn_learner(dls, config.model_arch, metrics=metrics, \n",
        "                      cbs = [SaveModelCallback(monitor=monitor, fname='best_model'),\n",
        "                             mixup])\n",
        "else:\n",
        "  learn = cnn_learner(dls, config.model_arch, metrics=metrics, \n",
        "                      cbs = [SaveModelCallback(monitor=monitor, fname='best_model')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiA9FliNPgHN"
      },
      "source": [
        "lr_min, lr_steep = learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnDffUj3PqLl"
      },
      "source": [
        "learn.fit_one_cycle(config.num_freeze_epochs, 3e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eihvHOeAXHSV"
      },
      "source": [
        "learn.recorder.plot_loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faRcqeTPhxu-"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fbCME0Gh2BT"
      },
      "source": [
        "learn.fit_one_cycle(config.num_epochs, lr_max=slice(3e-6,3e-4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2RD_zzTh894"
      },
      "source": [
        "learn.recorder.plot_loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvErnBWddzjM"
      },
      "source": [
        "learning_results = [('final_train_loss', learn.final_record[0]), \n",
        "                    ('final_val_loss', learn.final_record[1]),\n",
        "                    (f'final_{monitor}', learn.final_record[2])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m8og4j_WrNU"
      },
      "source": [
        "learning_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqtbxUuhGiqw"
      },
      "source": [
        "# Inspect results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpilGWdsnOUj"
      },
      "source": [
        "files = get_image_files('/content/data/test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QckXbbvCnXfb"
      },
      "source": [
        "learn.predict(files[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BqCLZruP4fs"
      },
      "source": [
        "learn.show_results(max_n=9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPqndC0TSiBJ"
      },
      "source": [
        "interp = Interpretation.from_learner(learn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le_FfDuOSqCF"
      },
      "source": [
        "interp.plot_top_losses(16, figsize=(15,10))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl1VVAKjQQRW"
      },
      "source": [
        "if not config.multi_class:\n",
        "  class_interp = ClassificationInterpretation.from_learner(learn)\n",
        "  class_interp.plot_confusion_matrix(title='Confusion matrix', figsize=(10,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT9aKrBZZvgk"
      },
      "source": [
        "if not config.multi_class:\n",
        "  class_interp.most_confused(min_val=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58R1KhvvL5WM"
      },
      "source": [
        "# Make prediction on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMFlmyhq001v"
      },
      "source": [
        "test_dl = dls.test_dl(get_image_files(data_dir/\"test\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbxs4LPd4Oe7"
      },
      "source": [
        "test_dl.show_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY8qYDMA1cVn"
      },
      "source": [
        "preds = learn.get_preds(dl=test_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F8JM9Zp48g-"
      },
      "source": [
        "pred_ind = torch.argmax(preds[0], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4Pqz3NG5pwD"
      },
      "source": [
        "pred_cat = [dls.vocab[p] for p in pred_ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwTfmCwKNii8"
      },
      "source": [
        "model_path = 'models/' + str(config)+'.pkl'\n",
        "learn.export(fname = model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux16dYVT6Tkm"
      },
      "source": [
        "test_files = get_image_files(data_dir/\"test\")\n",
        "test_files = test_files.map(lambda x :str(x).replace('/content/data','.') )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_iHO9xtNq26"
      },
      "source": [
        "predictions = {'image': test_files, 'sports': pred_cat}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIEb145rOFOI"
      },
      "source": [
        "pred_df = pd.DataFrame(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdZnFHxJSuLw"
      },
      "source": [
        "test_prediction_file = 'test_evaluation.csv'\n",
        "pred_df.to_csv(test_prediction_file, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf2zlmEJ2kJf"
      },
      "source": [
        "# Perform TTA on model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHhadk6q2wJl"
      },
      "source": [
        "Need to create two test dataloaders each covering one half of the test dataset (as tta is only applied on validation part, and we can't just have a dataloader with only validation). Run tta() over both those dataloaders and then concatenate the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXdNt23O87ti"
      },
      "source": [
        "test_dl = dls.test_dl(get_image_files(data_dir/\"test\"))\n",
        "preds = learn.tta(dl=test_dl)[0]\n",
        "pred_ind = torch.argmax(preds, axis=1)\n",
        "pred_cat = [dls.vocab[p] for p in pred_ind] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhfJvVx55RXp"
      },
      "source": [
        "tta_predictions = {'image': get_image_files(data_dir/\"test\"), 'sports': pred_cat}\n",
        "tta_pred_df = pd.DataFrame(tta_predictions)\n",
        "tta_pred_df.image = tta_pred_df.image.apply(lambda x : str(x).replace('/content/data', '.'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4smGXCT5Los"
      },
      "source": [
        "tta_test_prediction_file = 'tta_test_evaluation.csv'\n",
        "tta_pred_df.to_csv(tta_test_prediction_file, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfVfC_rW-BrY"
      },
      "source": [
        "# Interpretation using CAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaIZwLUN-Kht"
      },
      "source": [
        "class Hook:\n",
        "  def __init__(self, mod):\n",
        "    self.hook = mod.register_forward_hook(self.hook_func)\n",
        "  def hook_func(self, mod, inp, out): # module, input, output always required as input\n",
        "    self.stored = out.detach().clone()\n",
        "  def __enter__(self, *args):\n",
        "    return self\n",
        "  def __exit__(self, *args):  # to automatically remove hook to avoid memory leakage\n",
        "    self.hook.remove()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfpBASw0_i85"
      },
      "source": [
        "test_img, = first(dls.test_dl([get_image_files(data_dir/\"test\")[5]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkzwJqc3_CmJ"
      },
      "source": [
        "with Hook(learn.model[0]) as hook:\n",
        "  with torch.no_grad():\n",
        "    output = learn.model.eval()(test_img)\n",
        "  act = hook.stored[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loCbFPeX--gE"
      },
      "source": [
        "cam_map = torch.einsum('ck, kij->cij', learn.model[1][-1].weight, act)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSwBMsKyAqTo"
      },
      "source": [
        "im_dec = TensorImage(dls.train.decode((test_img,))[0][0]) # decoding needed due to normalization of loader\n",
        "_, ax = plt.subplots()\n",
        "im_dec.show(ctx=ax)\n",
        "ax.imshow(cam_map[1].detach().cpu(), alpha=0.6, extent = (0,224,224,0), interpolation='bilinear', cmap='jet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZh0h2EDHMNW"
      },
      "source": [
        "# Interpretation using GradCam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njgp_ThLH199"
      },
      "source": [
        "dls.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f1ZLrpCHSZ0"
      },
      "source": [
        "class HookBwd:\n",
        "  def __init__(self, mod):\n",
        "    self.hook = mod.register_backward_hook(self.hook_func)\n",
        "  def hook_func(self, mod, grad_inp, grad_out):\n",
        "    self.stored = grad_out[0].detach().clone()\n",
        "  def __enter__(self, *args):\n",
        "    return self\n",
        "  def __exit__(self, *args):\n",
        "    self.hook.remove()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZV-f6aPHnK1"
      },
      "source": [
        "class_idx = 0 # badminton\n",
        "layer_idx = -1\n",
        "with HookBwd(learn.model[0][layer_idx]) as hookg:\n",
        "  with Hook(learn.model[0][layer_idx]) as hook:\n",
        "    output = learn.model.eval()(test_img)\n",
        "    act = hook.stored\n",
        "  output[0, class_idx].backward()\n",
        "  grad = hookg.stored"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAEzLQb7IWjN"
      },
      "source": [
        "w = grad[0].mean(dim=[1,2], keepdim=True)\n",
        "cam_map = (w*act[0]).sum(0)\n",
        "\n",
        "im_dec = TensorImage(dls.train.decode((test_img,))[0][0]) # decoding needed due to normalization of loader\n",
        "_, ax = plt.subplots()\n",
        "im_dec.show(ctx=ax)\n",
        "ax.imshow(cam_map.detach().cpu(), alpha=0.6, extent = (0,224,224,0), interpolation='bilinear', cmap='jet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh2D0FXdGmab"
      },
      "source": [
        "# Log the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5B5rpkmvUn"
      },
      "source": [
        "import mlflow\n",
        "from mlflow import log_metric, log_param, log_artifacts,log_artifact"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3yIY2GcmrJX"
      },
      "source": [
        "mlflow.set_tracking_uri(str(mlflow_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-hdWr0Kmm2P"
      },
      "source": [
        "def get_max_run_id(experiment_id):\n",
        "    runs = mlflow.search_runs(experiment_ids=[experiment_id]) \n",
        "    run_id = len(runs)\n",
        "    return run_id\n",
        "\n",
        "def connect_to_experiment(experiment_name):\n",
        "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "    if experiment is None:\n",
        "        experiment_id = mlflow.create_experiment(experiment_name)\n",
        "        run_id = 1 \n",
        "    else:\n",
        "        experiment_id = experiment.experiment_id \n",
        "        run_id = get_max_run_id(experiment_id) \n",
        "    return experiment_id, run_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_oyBGbZs532"
      },
      "source": [
        "experiment_id, run_id = connect_to_experiment('sports_classification')\n",
        "mlflow.start_run(run_name='sports_classification_run', experiment_id=experiment_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvl4_k0ftHo4"
      },
      "source": [
        "for config_tuple in config.mlflow_config():\n",
        "  log_param(*config_tuple)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7hyWQSZth6t"
      },
      "source": [
        "for result_tuple in learning_results:\n",
        "  log_metric(*result_tuple)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqiyF_8_tzjA"
      },
      "source": [
        "log_artifact(model_path)\n",
        "log_artifact(test_prediction_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyjUCDbQIhmc"
      },
      "source": [
        "mlflow.end_run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAlJqBoan5D5"
      },
      "source": [
        "# Updating mlruns on to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC2zd2R0MNk3"
      },
      "source": [
        "!zip -r mlruns.zip mlruns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfYdBgPtoAbE"
      },
      "source": [
        "!rsync --info=progress2 mlruns.zip ./drive/My\\ Drive/SportsClassification/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah3rodANuf4P"
      },
      "source": [
        "# Loading existing model for further work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFLUe5X6uv0Y"
      },
      "source": [
        "experiment = mlflow.get_experiment_by_name('sports_classification')\n",
        "assert(experiment is not None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEfJxqkKuyoJ"
      },
      "source": [
        "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs2HX0E_vDNz"
      },
      "source": [
        "runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHz03WInvI7D"
      },
      "source": [
        "# artifact_uri = runs.artifact_uri.iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rRIm_skvaL5"
      },
      "source": [
        "# models = [str(f) for f in Path(artifact_uri).ls() if '.pkl' in str(f)]\n",
        "# assert(len(models)==1)\n",
        "# model = models[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N5qygpxvbsa"
      },
      "source": [
        "#learn = load_learner(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNe06oAI2cZT"
      },
      "source": [
        "# Onnx conversion and quality check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAFuO3727AEW"
      },
      "source": [
        "## Conversion to onnx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb47c-kg54GE"
      },
      "source": [
        "im_tensor = first(learn.dls[0])[0][:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaHv8Mp74MfY"
      },
      "source": [
        "torch.onnx.export(learn.model,               \n",
        "                  im_tensor,                         \n",
        "                  \"sports_classifier.onnx\",  \n",
        "                  export_params=True,        \n",
        "                  opset_version=10,          \n",
        "                  do_constant_folding=True,  \n",
        "                  input_names = ['input'],   \n",
        "                  output_names = ['output'], \n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    \n",
        "                                'output' : {0 : 'batch_size'}})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpMzNjsN4nN_"
      },
      "source": [
        "onnx_model = onnx.load(\"sports_classifier.onnx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBXxXZ3m7M0A"
      },
      "source": [
        "onnx.checker.check_model(onnx_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWW3vgvv7SDr"
      },
      "source": [
        "## Compute validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkdR4IMP7VCA"
      },
      "source": [
        "ort_session = onnxruntime.InferenceSession(\"sports_classifier.onnx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkvnCin47aM9"
      },
      "source": [
        "ctr = 0\n",
        "correct = 0\n",
        "for batch in learn.dls[0]:\n",
        "  im_batch, label_batch = batch\n",
        "  for im, label in zip(im_batch, label_batch):\n",
        "    ort_inputs = {ort_session.get_inputs()[0].name: np.expand_dims(im.cpu().numpy(),0)}\n",
        "    ort_outs = ort_session.run(None, ort_inputs)\n",
        "    predicted_label = np.argmax(ort_outs[0])\n",
        "    ctr += 1\n",
        "    if config.multi_class:\n",
        "      label = np.argmax(label.cpu().numpy())\n",
        "    correct += (predicted_label == label)\n",
        "print(f'Accuracy: {correct/ctr}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6VNmxWoQzeV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}